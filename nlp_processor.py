import re

def tokenize(text):
    return text.split()

def process_text(text):
    tokens = tokenize(text)
    return tokens  # Keeping suffixes as per your request
